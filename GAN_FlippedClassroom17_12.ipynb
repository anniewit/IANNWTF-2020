{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_FlippedClassroom17_12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrKum0UVLliz67D7houLGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniewit/IANNWTF-2020/blob/main/GAN_FlippedClassroom17_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poLUZl2QqTEY"
      },
      "source": [
        "How to calculate losses:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t323QXbVgiX"
      },
      "source": [
        "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "def generator_loss(d_pred): \r\n",
        "  \"\"\"\r\n",
        "  d_pred: discriminator's prediction  of the image generated by the generator  \r\n",
        "  take cross entropy between predicted label and all labels as 1s\r\n",
        "  because we want to minimize the difference between them\r\n",
        "  --> the more the discriminator thinks the images are real, the better our generator\r\n",
        "  \"\"\"\r\n",
        "  return bce(tf.ones_like(d_pred), d_pred) # tf.ones_like(d_pred) is same as tf.ones(d_pred.shape)\r\n",
        "\r\n",
        "\r\n",
        "def discriminator_loss(real_img_lbl, fake_img_lbl):\r\n",
        "  \"\"\"\r\n",
        "  real_img_lbl: labels that discriminator predicted when seeing real images (should ideally be all 1s)\r\n",
        "  fake_img_lbl: labels that discriminator predicted when seeing fake images (should ideally be all 0s)\r\n",
        "  \"\"\"\r\n",
        "  real_loss = bce(tf.ones(real_img_lbl.shape), real_img_lbl)\r\n",
        "  fake_loss = bce(tf.zeros(fake_img_lbl.shape), fake_img_lbl)\r\n",
        "\r\n",
        "  return real_loss + fake_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UukQ7EIvqeLp"
      },
      "source": [
        "\r\n",
        "Pseudo code of the GAN training step (simultaneous updating):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I06v5raVYpz0"
      },
      "source": [
        "# def training step(generator, discriminator, real_images):\r\n",
        "\r\n",
        "  # create noise\r\n",
        "  # feed into generator\r\n",
        "\r\n",
        "  # feed real images into discriminator, get the predictions\r\n",
        "  # feed fake images into discriminator, get the predictions\r\n",
        "  \r\n",
        "  # calculate discr loss \r\n",
        "  # apply the gradients\r\n",
        "\r\n",
        "  # calc gen loss\r\n",
        "  # apply gradients \r\n",
        "\r\n",
        "  # return both losses"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}